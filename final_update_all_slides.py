#!/usr/bin/env python3
"""
Final comprehensive update for all slides with complete information
"""

from pptx import Presentation

def update_all_slides():
    """Update all slides with comprehensive, accurate information"""

    prs = Presentation("CDCP_AI_Demo_Day_Complete.pptx")

    print("üìä Updating all slides with complete information...\n")

    # SLIDE 3: Solution (High-level features)
    print("‚úçÔ∏è Slide 3: SOLUTION")
    slide3 = prs.slides[2]

    # Clear all text first
    for shape in slide3.shapes:
        if hasattr(shape, "text_frame"):
            shape.text_frame.clear()

    slide3_content = """SOLUTION

CDCP AI: Voice-enabled chatbot for instant, accurate CDCP answers

Key Features & Innovation:

‚Ä¢ Multi-model AI architecture - Vector DB + Fine-tuned Llama-3.2-1B + GPT-4 evaluation and fallback

‚Ä¢ Smart RAG pipeline - Semantic search retrieves context, trained Llama generates answers

‚Ä¢ Dual-layer quality control - GPT-4 validates every answer; auto-fallback for out-of-scope or poor responses

‚Ä¢ Voice-enabled & multilingual - Natural conversation interface, accessible to all Canadians

‚Ä¢ Reduces dental clinic workload - Handles repetitive CDCP questions 24/7

Technology Stack:
Python FastAPI, LangChain, LangGraph, React/TypeScript, ChromaDB,
Llama-3.2-1B, GPT-4, Whisper ASR, Coqui TTS"""

    # Add to largest text box
    largest_shape = max(
        (s for s in slide3.shapes if hasattr(s, "text_frame")),
        key=lambda s: s.width * s.height,
        default=None
    )
    if largest_shape:
        p = largest_shape.text_frame.paragraphs[0]
        p.text = slide3_content

    # SLIDE 4: How It Works (Technical Architecture)
    print("‚úçÔ∏è Slide 4: HOW IT WORKS")
    slide4 = prs.slides[3]

    # Clear all text first
    for shape in slide4.shapes:
        if hasattr(shape, "text_frame"):
            shape.text_frame.clear()

    slide4_content = """HOW IT WORKS - Technical Architecture

End-to-End Voice Conversation Flow:
1. Voice Input ‚Üí Whisper ASR ‚Üí Text transcription
2. Query ‚Üí ChromaDB Vector Search ‚Üí Top 3 relevant CDCP documents
3. Context + Query ‚Üí Fine-tuned Llama-3.2-1B-Instruct ‚Üí Answer
4. Answer ‚Üí Supervisor Evaluation (GPT-4/Claude)
5. If GOOD: Answer ‚Üí Coqui TTS ‚Üí Voice Output
   If BAD: GPT-4 Fallback ‚Üí Coqui TTS ‚Üí Voice Output

RAG Pipeline Components:

Vector Database (ChromaDB):
‚Ä¢ Stores embeddings of official CDCP documentation (scraped from canada.ca)
‚Ä¢ Sentence-Transformers model: all-MiniLM-L6-v2
‚Ä¢ Semantic search retrieves top 3 most relevant document chunks
‚Ä¢ Chunk size: 512 tokens with 50 token overlap

Fine-tuned Model (Llama-3.2-1B-Instruct):
‚Ä¢ Base model: Meta's Llama-3.2-1B-Instruct
‚Ä¢ Training: Multi-dialogue Q&A approach on CDCP dataset
‚Ä¢ Generates context-aware, conversational answers
‚Ä¢ Optimized for accessible, clear responses

Quality Control (Dual-Model):
‚Ä¢ Supervisor LLM (GPT-4/Claude) evaluates every answer
‚Ä¢ Checks: CDCP-related? Accurate? Helpful?
‚Ä¢ Confidence scoring: HIGH/MEDIUM/LOW
‚Ä¢ Intelligent fallback to GPT-4 if quality is poor or out-of-scope

Agent Orchestration (LangGraph):
‚Ä¢ Multi-step workflow: ASR ‚Üí RAG ‚Üí Evaluation ‚Üí TTS
‚Ä¢ State management and tool routing
‚Ä¢ Intelligent decision-making based on quality scores

Data Ingestion Process:
‚Ä¢ Web scraping: Official canada.ca CDCP pages
‚Ä¢ Document chunking: 512 tokens per chunk
‚Ä¢ Embedding generation: Sentence-Transformers
‚Ä¢ Vector storage: ChromaDB persistent database

Technology Stack:
‚Ä¢ Agent: LangChain, LangGraph (orchestration & workflow)
‚Ä¢ Backend: Python, FastAPI
‚Ä¢ AI Models: Llama-3.2-1B (fine-tuned), GPT-4, Claude, Whisper
‚Ä¢ Voice: OpenAI Whisper (ASR), Coqui TTS (speech synthesis)
‚Ä¢ Database: ChromaDB vector store
‚Ä¢ Frontend: React 19, TypeScript, Webpack, Nx monorepo"""

    largest_shape = max(
        (s for s in slide4.shapes if hasattr(s, "text_frame")),
        key=lambda s: s.width * s.height,
        default=None
    )
    if largest_shape:
        p = largest_shape.text_frame.paragraphs[0]
        p.text = slide4_content

    # SLIDE 5: Impact & Results
    print("‚úçÔ∏è Slide 5: IMPACT & RESULTS")
    slide5 = prs.slides[4]

    for shape in slide5.shapes:
        if hasattr(shape, "text_frame"):
            shape.text_frame.clear()

    slide5_content = """IMPACT & RESULTS

Accessibility Improvements:
‚Ä¢ Voice-first interface removes literacy barriers
‚Ä¢ Multilingual support for diverse Canadian population
‚Ä¢ 24/7 availability - no wait times
‚Ä¢ Reduces dental clinic staff workload on routine questions

Technical Achievements:
‚Ä¢ Successfully scraped and ingested official CDCP documentation
‚Ä¢ Built end-to-end RAG pipeline with semantic search
‚Ä¢ Fine-tuned Llama-3.2-1B on CDCP Q&A dataset
‚Ä¢ Implemented dual-model quality control system
‚Ä¢ Integrated LangGraph for intelligent agent orchestration
‚Ä¢ Complete voice conversation pipeline (ASR ‚Üí AI ‚Üí TTS)

System Performance:
‚Ä¢ Semantic search retrieves relevant context accurately
‚Ä¢ Quality control ensures reliable, on-topic responses
‚Ä¢ Fallback mechanism handles out-of-scope questions gracefully
‚Ä¢ Real-time voice processing with acceptable latency

Value Proposition:
‚Ä¢ Dental clinics: Reduced time spent on repetitive CDCP inquiries
‚Ä¢ Canadians: Easy access to CDCP information regardless of literacy/language
‚Ä¢ Government: Scalable solution for public service information
‚Ä¢ Future: Can be adapted for other government programs

Future Potential:
‚Ä¢ Scale to provincial dental programs
‚Ä¢ Mobile app deployment for wider accessibility
‚Ä¢ Integration with official CDCP portal
‚Ä¢ Multi-language expansion beyond English
‚Ä¢ Voice authentication for personalized queries"""

    largest_shape = max(
        (s for s in slide5.shapes if hasattr(s, "text_frame")),
        key=lambda s: s.width * s.height,
        default=None
    )
    if largest_shape:
        p = largest_shape.text_frame.paragraphs[0]
        p.text = slide5_content

    # SLIDE 6: Challenges & Learnings
    print("‚úçÔ∏è Slide 6: CHALLENGES & LEARNINGS")
    slide6 = prs.slides[5]

    for shape in slide6.shapes:
        if hasattr(shape, "text_frame"):
            shape.text_frame.clear()

    slide6_content = """CHALLENGES & LEARNINGS

Technical Challenges:

Data Collection & Preparation:
‚Ä¢ Web scraping official CDCP documentation with proper structure
‚Ä¢ Chunking strategy to maintain context (512 tokens, 50 overlap)
‚Ä¢ Creating high-quality Q&A dataset for fine-tuning

Model Fine-Tuning:
‚Ä¢ Fine-tuning Llama-3.2-1B with limited compute resources
‚Ä¢ Multi-dialogue training approach for conversational responses
‚Ä¢ Balancing model size vs. accuracy vs. inference speed

RAG Pipeline:
‚Ä¢ Selecting optimal embedding model (Sentence-Transformers)
‚Ä¢ Determining right number of context documents (settled on top 3)
‚Ä¢ Managing retrieval-generation balance

Quality Control:
‚Ä¢ Implementing reliable evaluation metrics
‚Ä¢ Supervisor LLM prompt engineering for consistent evaluation
‚Ä¢ Handling edge cases and out-of-scope queries

Voice Processing:
‚Ä¢ Managing audio processing latency
‚Ä¢ Whisper ASR accuracy with different accents
‚Ä¢ Coqui TTS voice quality and naturalness
‚Ä¢ End-to-end voice pipeline integration

Key Learnings:

‚úì RAG significantly improves answer accuracy over standalone fine-tuned model
‚úì Dual-model architecture provides production-grade reliability
‚úì LangGraph offers flexible, maintainable agent orchestration
‚úì Quality control is essential for healthcare information systems
‚úì Voice interfaces require careful UX design for accessibility
‚úì Iterative testing and refinement crucial for performance
‚úì Multi-model approach balances accuracy, cost, and latency

Solution Approaches:
‚Ä¢ Comprehensive error logging for debugging
‚Ä¢ Incremental development: RAG ‚Üí Fine-tuning ‚Üí Voice ‚Üí Quality Control
‚Ä¢ Modular architecture for easy testing and iteration
‚Ä¢ Supervisor evaluation prevents hallucinations and off-topic responses"""

    largest_shape = max(
        (s for s in slide6.shapes if hasattr(s, "text_frame")),
        key=lambda s: s.width * s.height,
        default=None
    )
    if largest_shape:
        p = largest_shape.text_frame.paragraphs[0]
        p.text = slide6_content

    # SLIDE 7: Development Timeline
    print("‚úçÔ∏è Slide 7: DEVELOPMENT TIMELINE")
    slide7 = prs.slides[6]

    for shape in slide7.shapes:
        if hasattr(shape, "text_frame"):
            shape.text_frame.clear()

    slide7_content = """DEVELOPMENT TIMELINE & PROCESS

Phase 1: Research & Planning (Week 1-2)
‚Ä¢ CDCP documentation analysis
‚Ä¢ Technology stack selection (LangChain, LangGraph, FastAPI)
‚Ä¢ RAG vs. Fine-tuning vs. Hybrid approach evaluation
‚Ä¢ Architecture design (multi-model approach)

Phase 2: Data Collection & RAG Pipeline (Week 3-4)
‚Ä¢ Web scraping official CDCP documentation
‚Ä¢ Document chunking and embedding generation
‚Ä¢ ChromaDB vector database setup
‚Ä¢ RAG pipeline implementation and testing
‚Ä¢ Semantic search optimization

Phase 3: Model Fine-Tuning (Week 4-5)
‚Ä¢ Q&A dataset preparation from CDCP documentation
‚Ä¢ Llama-3.2-1B fine-tuning with multi-dialogue approach
‚Ä¢ Model evaluation and optimization
‚Ä¢ Integration with RAG pipeline

Phase 4: Quality Control System (Week 5-6)
‚Ä¢ Supervisor LLM implementation (GPT-4/Claude)
‚Ä¢ Evaluation prompt engineering
‚Ä¢ Dual-model architecture integration
‚Ä¢ Fallback mechanism for poor/out-of-scope answers

Phase 5: Voice Integration (Week 6-7)
‚Ä¢ OpenAI Whisper ASR integration
‚Ä¢ Coqui TTS setup and configuration
‚Ä¢ LangGraph agent orchestration
‚Ä¢ End-to-end voice pipeline testing

Phase 6: Frontend & Integration (Week 7-8)
‚Ä¢ React voice chatbot interface
‚Ä¢ Real-time audio recording and playback
‚Ä¢ API integration with Python backend
‚Ä¢ User experience refinement

Phase 7: Testing & Refinement (Week 8-9)
‚Ä¢ End-to-end system testing
‚Ä¢ Performance optimization
‚Ä¢ Edge case handling
‚Ä¢ Demo preparation and documentation

Team: Michael Cai (Solo Project)
Tools: VS Code, GitHub, Nx monorepo, Python virtual environments"""

    largest_shape = max(
        (s for s in slide7.shapes if hasattr(s, "text_frame")),
        key=lambda s: s.width * s.height,
        default=None
    )
    if largest_shape:
        p = largest_shape.text_frame.paragraphs[0]
        p.text = slide7_content

    # SLIDE 8: Thank You / Q&A
    print("‚úçÔ∏è Slide 8: THANK YOU")
    slide8 = prs.slides[7]

    for shape in slide8.shapes:
        if hasattr(shape, "text_frame"):
            shape.text_frame.clear()

    slide8_content = """THANK YOU

Questions?

Project Summary:
CDCP AI - Voice-enabled chatbot with multi-model architecture
Using RAG + Fine-tuned Llama + GPT-4 quality control

Key Technologies:
‚Ä¢ LangChain & LangGraph (agent orchestration)
‚Ä¢ Llama-3.2-1B-Instruct (fine-tuned)
‚Ä¢ ChromaDB (vector database)
‚Ä¢ Whisper ASR + Coqui TTS (voice)
‚Ä¢ FastAPI + React (full-stack)

Project Links:
‚Ä¢ GitHub: [Your GitHub URL]
‚Ä¢ Demo: [Live Demo URL if available]

Contact:
Michael Cai
Email: [Your Email]

Special Thanks:
‚Ä¢ AI Class Instructors & TAs
‚Ä¢ Canada.ca for CDCP documentation
‚Ä¢ Open Source Community (LangChain, Hugging Face, Meta)
‚Ä¢ Coqui TTS, OpenAI Whisper teams

Future Work:
‚Ä¢ Production deployment
‚Ä¢ Mobile app version
‚Ä¢ Expand to other government services
‚Ä¢ Multi-language support"""

    largest_shape = max(
        (s for s in slide8.shapes if hasattr(s, "text_frame")),
        key=lambda s: s.width * s.height,
        default=None
    )
    if largest_shape:
        p = largest_shape.text_frame.paragraphs[0]
        p.text = slide8_content

    # Save
    output_path = "CDCP_AI_Demo_Day_Complete.pptx"
    prs.save(output_path)
    print(f"\n‚úÖ All slides updated: {output_path}")

    return output_path

if __name__ == "__main__":
    try:
        output_file = update_all_slides()
        print(f"\nüéâ Complete presentation ready!")
        print(f"\nüìã Slide Summary:")
        print(f"   Slide 1: Title - CDCP AI")
        print(f"   Slide 2: Problem - Dental clinic workload & info access")
        print(f"   Slide 3: Solution - Multi-model features & benefits")
        print(f"   Slide 4: How It Works - Complete RAG + fine-tuning architecture")
        print(f"   Slide 5: Impact - Achievements & value proposition")
        print(f"   Slide 6: Challenges - Technical hurdles & learnings")
        print(f"   Slide 7: Timeline - 9-week development process")
        print(f"   Slide 8: Thank You - Q&A & future work")
        print(f"\nüìç Next: Open in PowerPoint and add screenshots/images!")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
